---
---

<!doctype html>
<html>
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Derek Damron's Resume</title>
	<link rel="stylesheet" type="text/css" href="css/resume_base.css">
	<link rel="stylesheet" type="text/css" href="css/resume_layout.css">
	<link rel="stylesheet" type="text/css" href="css/resume_skeleton.css">
	<link rel="shortcut icon" type="image/png" href="img/icon_blackcat_16.png">
</head>

<body>
<div class="container">
    <header class="three columns">
        <img src="images/professional_derek.jpg" class="me">
        <h1>Derek Damron</h1>
        <p>
            <a href="mailto:damrondm@gmail.com">damrondm@gmail.com</a><br/>
        </p>
        <p>
            (479) 774-1757
        </p>
        <p>
            <a href="derek-damron.github.io">derek-damron.github.io</a>
        </p>
    </header>
    <div class="thirteen columns clearfix">
		<section class="thirteen columns">
			<h1>Employment</h1>
			<article>
				<header>
					<h1>Data Scientist</h1>
					<span><address>Allstate @ Menlo Park, CA</address><time>June 2015 to Present</time></span>
				</header>
				<p>
					At Allstate I work with business partners to help them understand how their data can be utilized to make more intelligent decisions.
					I work primarily in R, Unix, SQL, and Python but also have some experience using Hive, Beeline, Impala, HTML, CSS, and JavaScript.
				</p>
				<p>
					Some of my projects at Allstate have included:
				</p>
				<p>
					<ul>
						<li>
							Leading a project with a technology group to understand the drivers of server and application outages.
							This work involved managing the scope of the project, communicating findings and next steps, and identifying opportunities for collaboration with business users.
						</li>
						<li>
							Improving Allstate's life insurance product by working with other data scientists, data engineers, and business stakeholders.
							This work has involved engineering additional features for building models, handling of data quality issues such as censoring and under-reporting, and identifying opportunities to improve collaboration.
						</li>
						<li>
							Building and maintaining a general-purpose data exploration tool in R and Shiny.
							This tool has been presented to and used by both other data scientists and business users.
						</li>
					</ul>				
				</p>
			</article>
			<article>
				<header>
					<h1>Quantitative Analyst and Research Consultant</h1>
					<span><address>Hanover Research @ Washington, DC</address><time>July 2013 to May 2015</time></span>
				</header>
				<p>
					At Hanover Research I helped our enterprise clients utilize their data to make smarter decisions.
					My responsibilities included conducting analyses, communicating results, and leading projects with junior analysts.
					I also helped formalize Hanover's quantitative offerings and frequently worked with internal executive leadership.
					I worked primarily in R.
				</p>
				<p>
					The projects I led at Hanover include:
			    </p>
				<p>
					<ul>
						<li>
							Segmented 45,000 products via cluster analysis by using 5 years of sales data to group together products with similar sales patterns across several product classes.
							These segmentations were used to predict product sales behavior across specific time periods based on metadata in order to improve future supply management and plan promotional incentives.
						</li>
						<li>
							Developed a prospect scoring system using logistic regression on data that included 360 demographic and psychographic variables on 4.7 million prospects and clients.
							This scoring system was then implemented into an internal database system to dynamically score new prospects for prioritization in future campaigns.
						</li>
					</ul>
				</p>
			</article>
			<article>
				<header>
					<h1>Database Analyst and Application Developer</h1>
					<span><address>Acxiom @ Little Rock, AR</address><time>June 2010 to Feb 2013</time></span>
				</header>
				<p>
					At Acxiom I worked with customer databases for a large financial services client.
					My responsibilities included translating business requirements into automated file processing and communicating these processes to business analysts for monitoring.  
					I worked primarily in Unix and SQL.  
				</p>
				<p>
					Some of my accomplishments include:
			    </p>
				<p>
					<ul>
						<li>
							Received Acxiom Gold Coin/Badge awards for training production associates and helping onboard a new client.
						</li>
						<li>
							Optimized file processing procedure to save roughly 20 hours in lost processing time per monthly work cycle by troubleshooting common processing errors.
						</li>
						<li>
							Designed a single automation platform in order to simplify the automated processing of over 100 files per week by consolidating several different automated procedures.
						</li>
					</ul>
				</p>
			</article>
			
			<h1>Education</h1>
			<article>
				<header>
					<h1>The George Washington University</h1>
					<span><address>Master’s degree, Statistics</address><time>2012 to 2014 (3.74 GPA)</time></span>
				</header>
				<p>
					Attended on a CCAS Fellowship Award with a curriculum focused on data mining and applied statistics.
				</p>
			</article>
			<article>
				<header>
					<h1>University of Central Arkansas</h1>
					<span><address>Bachelor’s degree, Mathematics</address><time>2006 to 2010 (3.97 GPA)</time></span>
				</header>
				<p>
					Graduated Summa Cum Laude from the UCA Honors College. 
				</p>
			</article>
			
		</section>
    </div>
</div>
</body>
</html>